{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1100b594-74f4-4f5a-88a6-b6474976845a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "import torch\n",
    "import cohere\n",
    "from langchain_cohere import ChatCohere\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.document_loaders.merge import MergedDataLoader\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Qdrant\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce3df65-48d3-4657-8951-df49882af33a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba79655-e806-4cad-bea6-0671de64f84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41acbb85-7208-4721-9b94-1ff816ccc739",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "b67c3dcf-c42e-457d-ac64-747d92e3433a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pdf loader\n",
    "def open_pdfs(file_paths):\n",
    "    opened_pdfs = []\n",
    "\n",
    "    for path in file_paths:\n",
    "        if path.lower().endswith('.pdf'):\n",
    "            try:\n",
    "                pdf_loader = PyPDFLoader(path)\n",
    "                pdf = pdf_loader.load()\n",
    "                opened_pdfs.append(pdf)\n",
    "            except Exception as e:\n",
    "                opened_pdfs.append(f\"Error opening {path}: {e}\")\n",
    "        else:\n",
    "            opened_pdfs.append(f\"Invalid file type: {path}\")\n",
    "\n",
    "    return opened_pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "e24af0b1-f307-4015-b175-447843566b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten nested PDF List, the only difference is I use the extend argument to flatten the list\n",
    "\n",
    "def open_pdfs(file_paths):\n",
    "    opened_pdfs = []\n",
    "\n",
    "    for path in file_paths:\n",
    "        if path.lower().endswith('.pdf'):\n",
    "            try:\n",
    "                pdf_loader = PyPDFLoader(path)\n",
    "                pdf = pdf_loader.load()\n",
    "                if isinstance(pdf, list):\n",
    "                    opened_pdfs.extend(pdf)\n",
    "                else:\n",
    "                    opened_pdfs.append(pdf)\n",
    "            except Exception as e:\n",
    "                opened_pdfs.append(f\"Error opening {path}: {e}\")\n",
    "        else:\n",
    "            opened_pdfs.append(f\"Invalid file type: {path}\")\n",
    "\n",
    "    return opened_pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "252d9ebd-0db4-4b4b-89d6-4c97ba925d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = ['', \n",
    "              '',]\n",
    "opened_pdfs = open_pdfs(file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b8c390-daf8-4398-97a0-3ee8aaf52c9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20160240-71c8-43cb-a1c0-fd44247291f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten nested MARKDOWN List\n",
    "\n",
    "def open_md(file_paths):\n",
    "    opened_md = []\n",
    "\n",
    "    for path in file_paths:\n",
    "        if path.lower().endswith('.md'):\n",
    "            try:\n",
    "                md_loader = TextLoader(path)\n",
    "                md = md_loader.load()\n",
    "                if isinstance(md, list):\n",
    "                    opened_md.extend(md)\n",
    "                else:\n",
    "                    opened_md.append(md)\n",
    "            except Exception as e:\n",
    "                opened_md.append(f\"Error opening {path}: {e}\")\n",
    "        else:\n",
    "            opened_md.append(f\"Invalid file type: {path}\")\n",
    "\n",
    "    return opened_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3cfa165-9530-468d-a2c6-987fde08f3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = ['',\n",
    "             '',]\n",
    "opened_md = open_md(file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd8da53-59e6-442d-a221-a8ad307c2db0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45688923-0ef7-4236-a996-e6da3e1beae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the documetns\n",
    "def text_splits(data, size: int, overlap: int):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=size, chunk_overlap=overlap)\n",
    "    chunks = text_splitter.split_documents(data)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c654c2f9-c3a6-4a69-997e-3807e7269648",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = text_splits(opened_md, 2048, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80539f9-2402-4d64-b894-6915d1eaf833",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfbd8de0-7af1-44ef-80f8-257eeb452978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load locally the embedding model that is downloaded from HuggingFace\n",
    "model_path = r''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7491026-10a1-442c-9324-93dff7c0a7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the embedding model into cpu\n",
    "def embedding_model(model_path):\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=model_path,\n",
    "                                       model_kwargs={'device': 'cpu'}, encode_kwargs={'device': 'cpu'}, \n",
    "                                  )\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0feadf26-627b-48b7-a115-da2a6faa7231",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = embedding_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f60f35-fd04-4d08-bb76-00e807167b5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3757e3d8-f859-48f2-a514-b44f266946ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load vectorstore and then the retriever\n",
    "def retriever_function(location):\n",
    "    vectorstore = Qdrant.from_documents(\n",
    "    splits,\n",
    "    embeddings,\n",
    "    #url=url,\n",
    "    #prefer_grpc=True,\n",
    "    #api_key=api_key,\n",
    "    location=location, \n",
    "    #collection_name=\"my_documents\"\n",
    "    )\n",
    "\n",
    "    retriever_model = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "    \n",
    "    return retriever_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd6fe3c5-72db-4854-9389-f27cb87b364a",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = retriever_function(location=\":memory:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d183664-a2a2-497c-b68d-d4f65957bcbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75b4cbe9-89cf-45c3-bd7a-9c5457fb77f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Prompt Template\n",
    "prompt_template = \"\"\"\"You are a bot for question-answering reviews for a business. \\\n",
    "Use the following pieces of retrieved context to answer the customer's review. \\\n",
    "Do not ask questions in your answer. \\\n",
    "Use we, the pronoun of the first person plural. \\\n",
    "Do not repeat the same phrases and words from the question in your answer. \\\n",
    "Exclude from your answer, words that are used in the question. \\\n",
    "Do not repeat yourself. \\\n",
    "Keep the answer concise.\\\n",
    "Only answer questions related to the business. \\\n",
    "Be less formal. \\\n",
    "Always try to satisfy and acknowledge long-time customers. \\\n",
    "INFORMATION: \\n{context}\\n\n",
    "QUESTION: \\n{question}\\n\n",
    "ANSWER:  \"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e8de3bf4-8e94-4eff-a61e-1851b857e96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The printed output sometimes prints \\n\\n, this replaces any unwanted issues\n",
    "def clean_string(s: str) -> str:\n",
    "    \"\"\"Replace newlines with a blank space in a string.\"\"\"\n",
    "    return re.sub(r'\\n+', '', s)\n",
    "\n",
    "def process_result(result):\n",
    "    \"\"\"Recursively process and clean strings within the result.\"\"\"\n",
    "    if isinstance(result, str):\n",
    "        return clean_string(result)\n",
    "    elif isinstance(result, dict):\n",
    "        return {key: process_result(value) for key, value in result.items()}\n",
    "    elif isinstance(result, list):\n",
    "        return [process_result(item) for item in result]\n",
    "    else:\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2931caf1-d3ae-4e0a-bee9-15c8ae716d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the chain and llm\n",
    "def get_conversation_chain(text:str):\n",
    "    llm = ChatCohere(cohere_api_key=\"\", model=\"command-r-plus\", max_tokens=512, \n",
    "                 temperature=0.1, verbose=True)\n",
    "\n",
    "    chain = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\",\n",
    "                                    retriever=retriever,\n",
    "                                    chain_type_kwargs={\"prompt\" : prompt, \"verbose\": False})\n",
    "\n",
    "    result = chain.invoke(text)\n",
    "\n",
    "    cleaned_result = process_result(result)\n",
    "    \n",
    "    return cleaned_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bed1592-078f-4eb9-8c9a-ca0f16cef314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask questions!\n",
    "get_conversation_chain(input())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c9fbc7-112a-4a4f-9276-7fb3c947357e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6c99b8-ac0c-45bc-a8be-f77e6b309caa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
